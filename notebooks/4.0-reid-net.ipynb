{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xABx3A-soZMM"
   },
   "source": [
    "#  CV3DST  ReID\n",
    "- to train a small ReID dataset with cross-entropy and triplet-loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFYSSMiwpxSq"
   },
   "source": [
    "#### Install and import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import motmetrics as mm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "mm.lap.default_solver = \"lap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reid_root_dir = \"..\"\n",
    "root_dir = \"..\"\n",
    "sys.path.append(os.path.join(reid_root_dir, \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load helper code\n",
    "from market import metrics, utils\n",
    "from market.datamanager import ImageDataManager\n",
    "from market.eval import evaluate\n",
    "from market.models import build_model\n",
    "from mot.tracker.base import Tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345\n",
    "seq_name = \"MOT16-reid\"  # We recommend to use this subset.\n",
    "data_dir = os.path.join(root_dir, \"data/MOT16\")\n",
    "output_dir = os.path.join(root_dir, \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5KgKxhmMm1r"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM5linhlJpC0"
   },
   "source": [
    "# Training a ReID Network\n",
    "\n",
    "train a simple ReID network on the Market data. we will use a ResNet34/ResNet50 neural network that extracts features from an input image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxrvjE5dK-jU"
   },
   "source": [
    "Next, create the the DataManager for the Market dataset that will provide the train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamanager = ImageDataManager(\n",
    "    root=reid_root_dir,\n",
    "    height=256,\n",
    "    width=128,\n",
    "    batch_size_train=32,\n",
    "    workers=2,\n",
    "    transforms=[\"random_flip\", \"random_crop\"],\n",
    ")\n",
    "train_loader = datamanager.train_loader\n",
    "test_loader = datamanager.test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2jjUmXPP__Y"
   },
   "source": [
    "Now, let's create a resnet34 model and move it to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    \"resnet34\", datamanager.num_train_pids, loss=\"softmax\", pretrained=True\n",
    ")\n",
    "model = model.cuda()\n",
    "\n",
    "trainable_params = model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYKGh1BvQUf7"
   },
   "source": [
    "For training the network, we now need to choose an optimizer and learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    trainable_params, lr=0.0003, weight_decay=5e-4, amsgrad=True\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8_QAhVZQfXB"
   },
   "source": [
    "The network will be trained on a cross-entropy loss, i.e., the network needs to classify each image to it's identity class. For $n$ different people, we will have $n$ different classes.\n",
    "\n",
    "During evaluation, we ignore the last classification layer and work on the extracted $feat$-dimensional features. This feature vector should be very similar for the same instance, and not similar for different instances.\n",
    "\n",
    "In the following, you have to implement two distance measurements:\n",
    "- Euclidian squared distance.\n",
    "- Cosine similarity.\n",
    "\n",
    "You are not allowed to change the interface of the function. Please have a look at the [Pytorch documentation](https://pytorch.org/docs/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mot.utils import cosine_distance, euclidean_squared_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsCwff40aCtK"
   },
   "source": [
    "With the implemented distance measure, we can now implement the evaluation function. We extract features for the query set and for the gallery set and then build a distance matrix based on your implemented distance measure.\n",
    "Select metric_fn one of:\n",
    "\n",
    "- cosine_distance\n",
    "- euclidean_squared_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fn = cosine_distance  # cosine_distance or euclidean_squared_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Gxtrj6HaqGU"
   },
   "source": [
    "Finally, we can implement the training logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCH = 30\n",
    "EPOCH_EVAL_FREQ = 5\n",
    "PRINT_FREQ = 50\n",
    "\n",
    "num_batches = len(train_loader)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    losses = utils.MetricMeter()\n",
    "    batch_time = utils.AverageMeter()\n",
    "    end = time.time()\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        # Predict output.\n",
    "        imgs, pids = data[\"img\"].cuda(), data[\"pid\"].cuda()\n",
    "        output = model(imgs)\n",
    "        # Compute loss.\n",
    "        loss = criterion(output, pids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        losses.update({\"Loss\": loss})\n",
    "        if (batch_idx + 1) % PRINT_FREQ == 0:\n",
    "            utils.print_statistics(\n",
    "                batch_idx, num_batches, epoch, MAX_EPOCH, batch_time, losses\n",
    "            )\n",
    "        end = time.time()\n",
    "\n",
    "    if (epoch + 1) % EPOCH_EVAL_FREQ == 0 or epoch == MAX_EPOCH - 1:\n",
    "        rank1, mAP = evaluate(model, test_loader)\n",
    "        print(\n",
    "            \"Epoch {0}/{1}: Rank1: {rank}, mAP: {map}\".format(\n",
    "                epoch + 1, MAX_EPOCH, rank=rank1, map=mAP\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Results **\n",
    "mAP: 56.6%\n",
    "CMC curve\n",
    "Rank-1  : 76.6%\n",
    "Rank-5  : 90.3%\n",
    "Rank-10 : 93.6%\n",
    "Rank-20 : 95.8%\n",
    "Epoch 30/30: Rank1: 0.7657363414764404, mAP: 0.565798018920044"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WTIXl8e5zOL"
   },
   "source": [
    "# Part II - Triplet loss and hard negative mining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V60_tz9l93xi"
   },
   "source": [
    "Now, we can combine both losses and train a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mot.models.reid_losses import CombinedLoss, HardBatchMiningTripletLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    \"resnet34\", datamanager.num_train_pids, loss=\"triplet\", pretrained=True\n",
    ")\n",
    "model = model.cuda()\n",
    "\n",
    "trainable_params = model.parameters()\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainable_params, lr=0.0003, weight_decay=5e-4, amsgrad=True\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCH = 30\n",
    "EPOCH_EVAL_FREQ = 5\n",
    "PRINT_FREQ = 10\n",
    "\n",
    "num_batches = len(train_loader)\n",
    "criterion = CombinedLoss(0.3, 1.0, 1.0)\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    losses = utils.MetricMeter()\n",
    "    batch_time = utils.AverageMeter()\n",
    "    end = time.time()\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        # Predict output.\n",
    "        imgs, pids = data[\"img\"].cuda(), data[\"pid\"].cuda()\n",
    "        logits, features = model(imgs)\n",
    "        # Compute loss.\n",
    "        loss, loss_summary = criterion(logits, features, pids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        losses.update(loss_summary)\n",
    "        if (batch_idx + 1) % PRINT_FREQ == 0:\n",
    "            utils.print_statistics(\n",
    "                batch_idx, num_batches, epoch, MAX_EPOCH, batch_time, losses\n",
    "            )\n",
    "        end = time.time()\n",
    "\n",
    "    if (epoch + 1) % EPOCH_EVAL_FREQ == 0 or epoch == MAX_EPOCH - 1:\n",
    "        rank1, mAP = evaluate(model, test_loader)\n",
    "        print(\n",
    "            \"Epoch {0}/{1}: Rank1: {rank}, mAP: {map}\".format(\n",
    "                epoch + 1, MAX_EPOCH, rank=rank1, map=mAP\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Results **\n",
    "mAP: 55.5%\n",
    "CMC curve\n",
    "Rank-1  : 76.7%\n",
    "Rank-5  : 90.3%\n",
    "Rank-10 : 93.3%\n",
    "Rank-20 : 95.6%\n",
    "Epoch 30/30: Rank1: 0.7666270732879639, mAP: 0.5549070795028802"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nSs-bUZqerq"
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = reid_root_dir + \"/models/resnet34_reid_market.model\"\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    \"resnet34\", datamanager.num_train_pids, loss=\"triplet\", pretrained=True\n",
    ")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reid_market_state_dict = torch.load(\n",
    "    model_path, map_location=lambda storage, loc: storage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(reid_market_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank1, mAP = evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0cafbbefa557af0eb434e43229a0bc3a94a7b3610e45211e67837890fcbccc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
