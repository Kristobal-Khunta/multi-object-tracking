{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xABx3A-soZMM"
   },
   "source": [
    "#  CV3DST  ReID\n",
    "- to train a small ReID dataset with cross-entropy and triplet-loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFYSSMiwpxSq"
   },
   "source": [
    "#### Install and import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15351,
     "status": "ok",
     "timestamp": 1658910410246,
     "user": {
      "displayName": "Максим Голдин",
      "userId": "08631407013133915158"
     },
     "user_tz": -180
    },
    "id": "KRMsynpFU6gh",
    "outputId": "cb3ecbe0-7e78-49d3-9aae-03fa8028006a"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "reid_root_dir = \"..\"\n",
    "root_dir = '..'\n",
    "sys.path.append(os.path.join(reid_root_dir, 'src'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5345,
     "status": "ok",
     "timestamp": 1658910415580,
     "user": {
      "displayName": "Максим Голдин",
      "userId": "08631407013133915158"
     },
     "user_tz": -180
    },
    "id": "RGOohkAgo-hW",
    "outputId": "0a2d2db4-fe9d-4ec4-c430-822c006681ff"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mot.data.data_track import MOT16Sequences\n",
    "from mot.data.data_obj_detect import MOT16ObjDetect\n",
    "from mot.models.object_detector import FRCNN_FPN\n",
    "from mot.tracker.base import Tracker\n",
    "from mot.transforms import (\n",
    "    obj_detect_transforms,\n",
    ")\n",
    "from mot.eval import get_mot_accum,evaluate_obj_detect, evaluate_mot_accums\n",
    "from mot.visualize import plot_sequence\n",
    "from mot.utils import ltrb_to_ltwh\n",
    "\n",
    "# Load helper code\n",
    "from market.datamanager import ImageDataManager\n",
    "from market.models import build_model\n",
    "from market import utils\n",
    "from market import metrics\n",
    "from market.eval import evaluate\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "import motmetrics as mm\n",
    "\n",
    "mm.lap.default_solver = \"lap\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1658910682779,
     "user": {
      "displayName": "Максим Голдин",
      "userId": "08631407013133915158"
     },
     "user_tz": -180
    },
    "id": "eQTAqnFptwul"
   },
   "outputs": [],
   "source": [
    "seed = 12345\n",
    "seq_name = \"MOT16-reid\"  # We recommend to use this subset.\n",
    "data_dir = os.path.join(root_dir, \"data/MOT16\")\n",
    "output_dir = os.path.join(root_dir, \"output\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5KgKxhmMm1r"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jV2c5yengHyC"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM5linhlJpC0"
   },
   "source": [
    "# Training a ReID Network\n",
    "\n",
    "train a simple ReID network on the Market data. we will use a ResNet34/ResNet50 neural network that extracts features from an input image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxrvjE5dK-jU"
   },
   "source": [
    "Next, create the the DataManager for the Market dataset that will provide the train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "filn9BvUKfYN"
   },
   "outputs": [],
   "source": [
    "datamanager = ImageDataManager(\n",
    "    root=reid_root_dir,\n",
    "    height=256,\n",
    "    width=128,\n",
    "    batch_size_train=32,\n",
    "    workers=2,\n",
    "    transforms=[\"random_flip\", \"random_crop\"],\n",
    ")\n",
    "train_loader = datamanager.train_loader\n",
    "test_loader = datamanager.test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2jjUmXPP__Y"
   },
   "source": [
    "Now, let's create a resnet34 model and move it to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lw5hhJ89KfVc"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    \"resnet34\", datamanager.num_train_pids, loss=\"softmax\", pretrained=True\n",
    ")\n",
    "model = model.cuda()\n",
    "\n",
    "trainable_params = model.parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYKGh1BvQUf7"
   },
   "source": [
    "For training the network, we now need to choose an optimizer and learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJAHcBToKfTY"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    trainable_params, lr=0.0003, weight_decay=5e-4, amsgrad=True\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8_QAhVZQfXB"
   },
   "source": [
    "The network will be trained on a cross-entropy loss, i.e., the network needs to classify each image to it's identity class. For $n$ different people, we will have $n$ different classes.\n",
    "\n",
    "During evaluation, we ignore the last classification layer and work on the extracted $feat$-dimensional features. This feature vector should be very similar for the same instance, and not similar for different instances.\n",
    "\n",
    "In the following, you have to implement two distance measurements:\n",
    "- Euclidian squared distance.\n",
    "- Cosine similarity.\n",
    "\n",
    "You are not allowed to change the interface of the function. Please have a look at the [Pytorch documentation](https://pytorch.org/docs/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mot.utils import euclidean_squared_distance, cosine_distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsCwff40aCtK"
   },
   "source": [
    "With the implemented distance measure, we can now implement the evaluation function. We extract features for the query set and for the gallery set and then build a distance matrix based on your implemented distance measure.\n",
    "Select metric_fn one of:\n",
    "\n",
    "- cosine_distance\n",
    "- euclidean_squared_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBP5mxLYXTAi"
   },
   "outputs": [],
   "source": [
    "metric_fn = cosine_distance  # cosine_distance or euclidean_squared_distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Gxtrj6HaqGU"
   },
   "source": [
    "Finally, we can implement the training logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGZF58_zKfR2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_EPOCH = 30\n",
    "EPOCH_EVAL_FREQ = 5\n",
    "PRINT_FREQ = 50\n",
    "\n",
    "num_batches = len(train_loader)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    losses = utils.MetricMeter()\n",
    "    batch_time = utils.AverageMeter()\n",
    "    end = time.time()\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        # Predict output.\n",
    "        imgs, pids = data[\"img\"].cuda(), data[\"pid\"].cuda()\n",
    "        output = model(imgs)\n",
    "        # Compute loss.\n",
    "        loss = criterion(output, pids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        losses.update({\"Loss\": loss})\n",
    "        if (batch_idx + 1) % PRINT_FREQ == 0:\n",
    "            utils.print_statistics(\n",
    "                batch_idx, num_batches, epoch, MAX_EPOCH, batch_time, losses\n",
    "            )\n",
    "        end = time.time()\n",
    "\n",
    "    if (epoch + 1) % EPOCH_EVAL_FREQ == 0 or epoch == MAX_EPOCH - 1:\n",
    "        rank1, mAP = evaluate(model, test_loader)\n",
    "        print(\n",
    "            \"Epoch {0}/{1}: Rank1: {rank}, mAP: {map}\".format(\n",
    "                epoch + 1, MAX_EPOCH, rank=rank1, map=mAP\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Results **\n",
    "mAP: 56.6%\n",
    "CMC curve\n",
    "Rank-1  : 76.6%\n",
    "Rank-5  : 90.3%\n",
    "Rank-10 : 93.6%\n",
    "Rank-20 : 95.8%\n",
    "Epoch 30/30: Rank1: 0.7657363414764404, mAP: 0.565798018920044"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WTIXl8e5zOL"
   },
   "source": [
    "# Part II - Triplet loss and hard negative mining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V60_tz9l93xi"
   },
   "source": [
    "Now, we can combine both losses and train a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mot.models.reid_losses import CombinedLoss, HardBatchMiningTripletLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9bam06cQb7q"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    \"resnet34\", datamanager.num_train_pids, loss=\"triplet\", pretrained=True\n",
    ")\n",
    "model = model.cuda()\n",
    "\n",
    "trainable_params = model.parameters()\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainable_params, lr=0.0003, weight_decay=5e-4, amsgrad=True\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mdJLCUKt5qJX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxjVrejKQb4y",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_EPOCH = 30\n",
    "EPOCH_EVAL_FREQ = 5\n",
    "PRINT_FREQ = 10\n",
    "\n",
    "num_batches = len(train_loader)\n",
    "criterion = CombinedLoss(0.3, 1.0, 1.0)\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    losses = utils.MetricMeter()\n",
    "    batch_time = utils.AverageMeter()\n",
    "    end = time.time()\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        # Predict output.\n",
    "        imgs, pids = data[\"img\"].cuda(), data[\"pid\"].cuda()\n",
    "        logits, features = model(imgs)\n",
    "        # Compute loss.\n",
    "        loss, loss_summary = criterion(logits, features, pids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        losses.update(loss_summary)\n",
    "        if (batch_idx + 1) % PRINT_FREQ == 0:\n",
    "            utils.print_statistics(\n",
    "                batch_idx, num_batches, epoch, MAX_EPOCH, batch_time, losses\n",
    "            )\n",
    "        end = time.time()\n",
    "\n",
    "    if (epoch + 1) % EPOCH_EVAL_FREQ == 0 or epoch == MAX_EPOCH - 1:\n",
    "        rank1, mAP = evaluate(model, test_loader)\n",
    "        print(\n",
    "            \"Epoch {0}/{1}: Rank1: {rank}, mAP: {map}\".format(\n",
    "                epoch + 1, MAX_EPOCH, rank=rank1, map=mAP\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Results **\n",
    "mAP: 55.5%\n",
    "CMC curve\n",
    "Rank-1  : 76.7%\n",
    "Rank-5  : 90.3%\n",
    "Rank-10 : 93.3%\n",
    "Rank-20 : 95.6%\n",
    "Epoch 30/30: Rank1: 0.7666270732879639, mAP: 0.5549070795028802"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nSs-bUZqerq"
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = reid_root_dir + \"/models/resnet34_reid_market.model\"\n",
    "model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    \"resnet34\", datamanager.num_train_pids, loss=\"triplet\", pretrained=True\n",
    ")\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reid_market_state_dict = torch.load(\n",
    "    model_path, map_location=lambda storage, loc: storage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(reid_market_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank1, mAP = evaluate(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Exercise_ReID.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0cafbbefa557af0eb434e43229a0bc3a94a7b3610e45211e67837890fcbccc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
