{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xABx3A-soZMM"
   },
   "source": [
    "# Computer Vision III: Detection, Segmentation and Tracking (CV3DST) GNN \n",
    "\n",
    "We will implement a Message Passing Network from scratch, and we will use to build a model that will learn to combine position information and reid features to directly predict associations between past tracks and detections. We will use this model to create robust tracker. \n",
    "- Implement a Message Passing Network from scratch to operate on bipartite graphs\n",
    "- Implement the pairwise feature  computation to obtain features for our Message Passing Network\n",
    "- Train the Message Passing Network and improve your tracker's IDF1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFYSSMiwpxSq"
   },
   "source": [
    "#### Install and import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KRMsynpFU6gh"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "RGOohkAgo-hW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tracker.data_track import MOT16Sequences\n",
    "from tracker.tracker import Tracker, ReIDTracker\n",
    "from tracker.predef_tracker import LongTermReIDHungarianPredefTracker\n",
    "from tracker.utils import run_tracker, cosine_distance\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "import os.path as osp\n",
    "\n",
    "import motmetrics as mm\n",
    "mm.lap.default_solver = 'lap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_dir = \"..\"\n",
    "sys.path.append(os.path.join(root_dir, 'src'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qubi7uE6EPd"
   },
   "source": [
    "## Speed-Ups\n",
    "In order to speed up training and inference runtimes, in this exercise we will be working with pre-computed detections and ReID embeddings. We ran the object detector we provided in Exercise 0 and applied to all frames. We also computed reid embeddings for all boxes in every frame of the dataset so that they don't need to be computed every time you run your tracker. This yields over 10x speed improvements. You will not have to work directly with the resulting files, as we have internally adapted the boilerplate code to work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gnn_root_dir\n",
    "#root_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tESJ1I1n7ot1"
   },
   "outputs": [],
   "source": [
    "train_db = torch.load(osp.join(root_dir, 'data/preprocessed_data/preprocessed_data_train_2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "S6ZQRUbo7ot2"
   },
   "outputs": [],
   "source": [
    "_UNMATCHED_COST = 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dZ1vBklj7ot3"
   },
   "outputs": [],
   "source": [
    "val_sequences = MOT16Sequences('MOT16-reid', root_dir = osp.join(root_dir, 'data/MOT16'), vis_threshold=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBeSJrY87ot7"
   },
   "source": [
    "## Building a tracker based on Neural Message Passing\n",
    "\n",
    "Our ``LongTermReIDHungarianTracker`` is still limited when compared to current modern trackers. \n",
    "\n",
    "Firstly, it relies solely on appearance to predict similarity scores between objectes. This can be problematic whenever appearance alone may not discriminative, and it'd be best to also take into account object position and size attributes. Secondly, our tracker can only account for pairwise similarities among objects. Ideally, we would like it to also consider higher-order information.\n",
    "\n",
    "To address these limitations. We will now build a tracker that will combine both apperance and position information with a Message Passing Neural Network, inspired by the approach presented in [Learning a Neural Solver for Multiple Object Tracking, CVPR 2020](https://arxiv.org/abs/1912.07515)\n",
    "\n",
    "The overall idea will be to build, for every tracking step, a bipartite graph containing two sets of nodes: past tracks, and detections in the current frame. We will initialize node features with ReID embeddings, and edge features with relative position features and ReID distance. We will use an MPN to refine these edge embeddings. The learning task will be to classify the edge embeddings in this graph, which is equivalent to predicting the entries of our data association similarity matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVbnOrlPqWRB"
   },
   "source": [
    "### Building an MPN for Bipartite Graphs\n",
    "\n",
    "We will first build a Neural Message Passing layer based on the Graph Networks framework introduced in [Relational inductive biases, deep learning, and graph networks, arXiv 2020](https://arxiv.org/abs/1806.01261), as explained in the *A More General Framework*\n",
    "\n",
    "We will be using a bipartite graph, i.e., we will have two sets of nodes $A$ (past tracks), and $B$ (detections), and our set of edges will be $A\\times B$. That is, we will connect every pair of past tracks and detections.\n",
    "\n",
    "We will have initial node features (i.e. reid embeddings) matrices: $X_A$ and $X_B$ and an initial edge features tensor $E$.\n",
    "\n",
    "$X_A$ and $X_B$ have shape $|A|\\times \\text{node\\_dim}$ and $|B|\\times \\text{node\\_dim}$, respectively.\n",
    "\n",
    "$E$ has shape $|A| \\times |B| \\times \\text{edge\\_dim}$. Its $(i, j)$ entry contains the edge features of node $i$ in $A$ and node $j$ in $B$.\n",
    "\n",
    "With the given layer, we will produce new node feature matrices $X_A'$ and $X_B'$ and edge features $E'$ with the same dimensions. \n",
    "Please refer to the formulas in the slides and figure how to apply them in this setting.\n",
    "\n",
    "You are asked to implement both the node and edge update steps in the class below\n",
    "\n",
    "**NOTE 1**: Working with a bipartite graph allows us to vectorize all operations in the formulas in a straightforward manner (keep in mind that we store edge features in a matrix). Given a node in $A$, it is connected to all nodes in $B$.\n",
    "\n",
    "**NOTE 2**: You do not need to care about batching several graphs. This implementation will only work with a single graph at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "4q2I6Luo7ot7"
   },
   "outputs": [],
   "source": [
    "\n",
    "class BipartiteNeuralMessagePassingLayer(nn.Module):    \n",
    "    def __init__(self, node_dim, edge_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "\n",
    "        edge_in_dim  = 2*node_dim + 2*edge_dim # 2*edge_dim since we always concatenate initial edge features\n",
    "        self.edge_mlp = nn.Sequential(*[nn.Linear(edge_in_dim, edge_dim), nn.ReLU(), nn.Dropout(dropout), \n",
    "                                    nn.Linear(edge_dim, edge_dim), nn.ReLU(), nn.Dropout(dropout)])\n",
    "\n",
    "        node_in_dim  = node_dim + edge_dim\n",
    "        self.node_mlp = nn.Sequential(*[nn.Linear(node_in_dim, node_dim), nn.ReLU(), nn.Dropout(dropout),  \n",
    "                                        nn.Linear(node_dim, node_dim), nn.ReLU(), nn.Dropout(dropout)])\n",
    "\n",
    "    def edge_update(self, edge_embeds, nodes_a_embeds, nodes_b_embeds):\n",
    "        \"\"\"\n",
    "        Node-to-edge updates, as descibed in slide 71, lecture 5.\n",
    "        Args:\n",
    "            edge_embeds: torch.Tensor with shape (|A|, |B|, 2 x edge_dim) \n",
    "            nodes_a_embeds: torch.Tensor with shape (|A|, node_dim)\n",
    "            nodes_a_embeds: torch.Tensor with shape (|B|, node_dim)\n",
    "            \n",
    "        returns:\n",
    "            updated_edge_feats = torch.Tensor with shape (|A|, |B|, edge_dim) \n",
    "        \"\"\"\n",
    "        n_nodes_a, n_nodes_b, _  = edge_embeds.shape\n",
    "        nodes_a_in = nodes_a_embeds.unsqueeze(1).expand((n_nodes_a, n_nodes_b, -1))\n",
    "        nodes_b_in = nodes_b_embeds.unsqueeze(0).expand((n_nodes_a, n_nodes_b, -1))\n",
    "\n",
    "        # edge_in has shape (|A|, |B|, 2*node_dim + 2*edge_dim) \n",
    "        edge_in = torch.cat((nodes_a_in, edge_embeds, nodes_b_in), dim=-1) \n",
    "        return self.edge_mlp(edge_in)\n",
    "\n",
    "    def node_update(self, edge_embeds, nodes_a_embeds, nodes_b_embeds):\n",
    "        \"\"\"\n",
    "        Edge-to-node updates, as descibed in slide 75, lecture 5.\n",
    "\n",
    "        Args:\n",
    "            edge_embeds: torch.Tensor with shape (|A|, |B|, edge_dim) \n",
    "            nodes_a_embeds: torch.Tensor with shape (|A|, node_dim)\n",
    "            nodes_b_embeds: torch.Tensor with shape (|B|, node_dim)\n",
    "            \n",
    "        returns:\n",
    "            tuple(\n",
    "                updated_nodes_a_embeds: torch.Tensor with shape (|A|, node_dim),\n",
    "                updated_nodes_b_embeds: torch.Tensor with shape (|B|, node_dim)\n",
    "                )\n",
    "        \"\"\"\n",
    "\n",
    "        # Use 'sum' as aggregation function\n",
    "        # aggreagete information about all connections of node A\n",
    "        # in each row - sum over edge embeddings with neighborn\n",
    "        nodes_a_neigh_embeds = torch.sum(edge_embeds, axis=1) # shape (|A|, |B|, edge_dim) sum over B\n",
    "        nodes_b_neigh_embeds = torch.sum(edge_embeds, axis=0) # shape (|A|, |B|, edge_dim) sum over A\n",
    "        nodes_a_in = torch.cat((nodes_a_embeds, nodes_a_neigh_embeds),dim=-1)  # Has shape (|A|, node_dim + edge_dim) \n",
    "        nodes_b_in = torch.cat((nodes_b_embeds, nodes_b_neigh_embeds,),dim=-1) # Has shape (|B|, node_dim + edge_dim) \n",
    "\n",
    "\n",
    "        nodes_a = self.node_mlp(nodes_a_in)\n",
    "        nodes_b = self.node_mlp(nodes_b_in)\n",
    "\n",
    "        return nodes_a, nodes_b\n",
    "\n",
    "    def forward(self, edge_embeds, nodes_a_embeds, nodes_b_embeds):\n",
    "        edge_embeds_latent = self.edge_update(edge_embeds, nodes_a_embeds, nodes_b_embeds)\n",
    "        nodes_a_latent, nodes_b_latent = self.node_update(edge_embeds_latent, nodes_a_embeds, nodes_b_embeds)\n",
    "\n",
    "        return edge_embeds_latent, nodes_a_latent, nodes_b_latent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2sPoUo07ot8"
   },
   "source": [
    "## Building the entire network to predict similarities\n",
    "We now build the network that generates initial node and edge features, performs neural message passing, and classifies edges in order to produce the final costs that we will use for data association.\n",
    "\n",
    "we  implement the method that computes the initial edge features. You can can follow [1] and, given a two bounding boxes $(x_i, y_i, w_i, h_i)$ and  $(x_j, y_j, w_j, h_j)$ and timestamps $t_i$ and $t_j$, compute an initial 5-dimensional edge feature vector as:\n",
    "$$ E_(i, j) = \\left (\\frac{2(x_j - x_i)}{h_i + h_j}, \\frac{2(y_j - y_i)}{h_i + h_j}, \\log{\\frac{h_i}{h_j}}, \\log{\\frac{w_i}{w_j}}, t_j - t_i \\right )$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ltrb_to_xcycwh(ltrb_boxes):\n",
    "    xcycwh = copy.deepcopy(ltrb_boxes)\n",
    "    xcycwh[:, 0] = (ltrb_boxes[:, 2] + ltrb_boxes[:, 0])/2 # x_ceter = (rx+lx)/2\n",
    "    xcycwh[:, 1] = (ltrb_boxes[:, 3] + ltrb_boxes[:, 1])/2 # \n",
    "    xcycwh[:, 2] = ltrb_boxes[:, 2] - ltrb_boxes[:, 0]\n",
    "    xcycwh[:, 3] = ltrb_boxes[:, 3] - ltrb_boxes[:, 1]\n",
    "    return xcycwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "id": "nF7apF9C7ot8"
   },
   "outputs": [],
   "source": [
    "class AssignmentSimilarityNet(nn.Module):\n",
    "    def __init__(self, reid_network, node_dim, edge_dim, reid_dim, edges_in_dim, num_steps, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.reid_network = reid_network\n",
    "        self.graph_net = BipartiteNeuralMessagePassingLayer(node_dim=node_dim, edge_dim=edge_dim, dropout=dropout)\n",
    "        self.num_steps = num_steps\n",
    "        self.cnn_linear = nn.Linear(reid_dim, node_dim)\n",
    "        self.edge_in_mlp = nn.Sequential(*[\n",
    "            nn.Linear(edges_in_dim, edge_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(edge_dim, edge_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(*[nn.Linear(edge_dim, edge_dim), nn.ReLU(), nn.Linear(edge_dim, 1)])\n",
    "        \n",
    "    \n",
    "    def compute_edge_feats(self, track_coords, current_coords, track_t, curr_t):    \n",
    "        \"\"\"\n",
    "        Computes initial edge feature tensor\n",
    "\n",
    "        Args:\n",
    "            track_coords: track's frame box coordinates, given by top-left and bottom-right coordinates\n",
    "                          torch.Tensor with shape (num_tracks, 4)\n",
    "            current_coords: current frame box coordinates, given by top-left and bottom-right coordinates\n",
    "                            has shape (num_boxes, 4)\n",
    "                          \n",
    "            track_t: track's timestamps, torch.Tensor with with shape (num_tracks, )\n",
    "            curr_t: current frame's timestamps, torch.Tensor withwith shape (num_boxes,)        \n",
    "            \n",
    "        \n",
    "        Returns:\n",
    "            tensor with shape (num_trakcs, num_boxes, 5) containing pairwise\n",
    "            position and time difference features \n",
    "        \"\"\"\n",
    "\n",
    "        num_boxes = current_coords.shape[0]\n",
    "        num_tracks = track_coords.shape[0]\n",
    "        \n",
    "        track_coords = ltrb_to_xcycwh(track_coords)\n",
    "        current_coords = ltrb_to_xcycwh(current_coords)\n",
    "       \n",
    "        track_coords = track_coords.unsqueeze_(1).expand(num_tracks,num_boxes, 4)\n",
    "        current_coords = current_coords.unsqueeze_(0).expand(num_tracks,num_boxes, 4)\n",
    "\n",
    "        dist_y = track_coords[...,1] - current_coords[...,1]\n",
    "        dist_x = track_coords[...,0] - current_coords[...,0]\n",
    "        denom = (track_coords[...,2] + current_coords[...,2])/2\n",
    "        dist_x = dist_x / denom\n",
    "        dist_y = dist_y / denom\n",
    "        \n",
    "        dist_w = torch.log(current_coords[...,2] / track_coords[...,2])\n",
    "        dist_h = torch.log(current_coords[...,3]  / track_coords[...,3])\n",
    "        \n",
    "        curr_t = curr_t.unsqueeze(0)#.expand(num_tracks,num_boxes)\n",
    "        track_t = track_t.unsqueeze(1)#.expand(num_tracks, num_boxes) \n",
    "        dist_t = (curr_t - track_t).type(dist_h.dtype)\n",
    "        \n",
    "        edge_feats = torch.stack([dist_x,dist_y, dist_w, dist_h, dist_t],dim=-1)\n",
    "        \n",
    "        return edge_feats # has shape (num_trakcs, num_boxes, 5)\n",
    "\n",
    "\n",
    "    def forward(self, track_app, current_app, track_coords, current_coords, track_t, curr_t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            track_app: track's reid embeddings, torch.Tensor with shape (num_tracks, 512)\n",
    "            current_app: current frame detections' reid embeddings, torch.Tensor with shape (num_boxes, 512)\n",
    "            track_coords: track's frame box coordinates, given by top-left and bottom-right coordinates\n",
    "                          torch.Tensor with shape (num_tracks, 4)\n",
    "            current_coords: current frame box coordinates, given by top-left and bottom-right coordinates\n",
    "                            has shape (num_boxes, 4)\n",
    "                          \n",
    "            track_t: track's timestamps, torch.Tensor with with shape (num_tracks, )\n",
    "            curr_t: current frame's timestamps, torch.Tensor withwith shape (num_boxes,)\n",
    "            \n",
    "        Returns:\n",
    "            classified edges: torch.Tensor with shape (num_steps, num_tracks, num_boxes),\n",
    "                             containing at entry (step, i, j) the unnormalized probability that track i and \n",
    "                             detection j are a match, according to the classifier at the given neural message passing step\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get initial edge embeddings to\n",
    "        dist_reid = cosine_distance(track_app, current_app)\n",
    "        pos_edge_feats = self.compute_edge_feats(track_coords, current_coords, track_t, curr_t)\n",
    "        edge_feats = torch.cat((pos_edge_feats, dist_reid.unsqueeze(-1)), dim=-1)\n",
    "        edge_embeds = self.edge_in_mlp(edge_feats)\n",
    "        initial_edge_embeds = edge_embeds.clone()\n",
    "\n",
    "        # Get initial node embeddings, reduce dimensionality from 512 to node_dim\n",
    "        track_embeds = F.relu(self.cnn_linear(track_app))\n",
    "        curr_embeds =F.relu(self.cnn_linear(current_app))\n",
    "\n",
    "        classified_edges = []\n",
    "        for _ in range(self.num_steps):\n",
    "            edge_embeds = torch.cat((edge_embeds, initial_edge_embeds), dim=-1)            \n",
    "            edge_embeds, track_embeds, curr_embeds = self.graph_net(edge_embeds=edge_embeds, \n",
    "                                                                    nodes_a_embeds=track_embeds, \n",
    "                                                                    nodes_b_embeds=curr_embeds)\n",
    "\n",
    "            classified_edges.append(self.classifier(edge_embeds))\n",
    "\n",
    "        return torch.stack(classified_edges).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Cdr6YDY7ot8"
   },
   "source": [
    "## Putting everything together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xp3cC6j57ot9"
   },
   "source": [
    "Finally,incorporate our ``AssignmentSimilarityNet`` into our tracker. We can keep everything as in ``LongTermReIDHungarianTracker`` except for the distance computation, which is now directly obtained via a forward pass through AssignmentSimilarityNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracker.predef_tracker import LongTermReIDHungarianPredefTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "id": "6GA99XOv7ot9"
   },
   "outputs": [],
   "source": [
    "_UNMATCHED_COST=255\n",
    "class MPNTracker(LongTermReIDHungarianPredefTracker):\n",
    "    def __init__(self, assign_net, *args, **kwargs):\n",
    "        self.assign_net = assign_net\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def data_association(self, boxes, scores, pred_features):  \n",
    "        if self.tracks:  \n",
    "            track_boxes = torch.stack([t.box for t in self.tracks], axis=0).cuda()\n",
    "            track_features = torch.stack([t.get_feature() for t in self.tracks], axis=0).cuda()\n",
    "            \n",
    "            # Hacky way to recover the timestamps of boxes and tracks\n",
    "            curr_t = self.im_index * torch.ones((pred_features.shape[0],)).cuda()\n",
    "            track_t = torch.as_tensor([self.im_index - t.inactive - 1 for t in self.tracks]).cuda()\n",
    "            \n",
    "            # Do a forward pass through self.assign_net to obtain our costs.\n",
    "            edges_raw_logits = self.assign_net(\n",
    "                track_features.cuda(),\n",
    "                pred_features.cuda(),\n",
    "                track_boxes.cuda(),\n",
    "                boxes.cuda(),\n",
    "                track_t,\n",
    "                curr_t\n",
    "            )\n",
    "            # Note: self.assign_net will return unnormalized probabilities. \n",
    "            # apply the sigmoid function to them!\n",
    "            pred_sim = torch.sigmoid(edges_raw_logits).detach().cpu().numpy()\n",
    "            pred_sim = pred_sim[-1]  # Use predictions at last message passing step\n",
    "            distance = (1- pred_sim) \n",
    "            \n",
    "            # Do not allow mataches when sim < 0.5, to avoid low-confident associations\n",
    "            distance = np.where(pred_sim < 0.5, _UNMATCHED_COST, distance) \n",
    "\n",
    "            # Perform Hungarian matching.\n",
    "            row_idx, col_idx = linear_assignment(distance)            \n",
    "            self.update_tracks(row_idx, col_idx,distance, boxes, scores, pred_features)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            # No tracks exist.\n",
    "            self.add(boxes, scores, pred_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyzMUfYE7ot9"
   },
   "source": [
    "## Training and evaluating our model\n",
    "\n",
    "We provide all boilerplate code for training our neural message passing based\n",
    "tracker, as well as evaluating. \n",
    "\n",
    "Under the hood, we are sampling frames randomly from our training sequences, and then sampling boxes from past frames as past_tracks to generate our \n",
    "training\n",
    "data. Check out `LongTrackTrainingDataset` for details.\n",
    "\n",
    "We train the model with a weighted cross-entropy loss\n",
    "to account for the class imbalance. Check out `train_one_epoch` if you're \n",
    "interested.\n",
    "\n",
    "No need to write any code from your side here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "id": "kuYy1IMK7ot9"
   },
   "outputs": [],
   "source": [
    "from gnn.dataset import LongTrackTrainingDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from gnn.trainer import train_one_epoch\n",
    "\n",
    "MAX_PATIENCE = 20\n",
    "MAX_EPOCHS = 15\n",
    "EVAL_FREQ = 1\n",
    "\n",
    "\n",
    "# Define our model, and init \n",
    "assign_net = AssignmentSimilarityNet(reid_network=None, # Not needed since we work with precomputed features\n",
    "                                     node_dim=32, \n",
    "                                     edge_dim=64, \n",
    "                                     reid_dim=512, \n",
    "                                     edges_in_dim=6, \n",
    "                                     num_steps=10).cuda()\n",
    "\n",
    "# We only keep two sequences for validation. You can\n",
    "dataset = LongTrackTrainingDataset(dataset='MOT16-train_wo_val2', \n",
    "                                   db=train_db, \n",
    "                                   root_dir= osp.join(root_dir, 'data/MOT16'),\n",
    "                                   max_past_frames = MAX_PATIENCE,\n",
    "                                   vis_threshold=0.25)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=8, collate_fn = lambda x: x, \n",
    "                         shuffle=True, num_workers=2, drop_last=True)\n",
    "device = torch.device('cuda')\n",
    "optimizer = torch.optim.Adam(assign_net.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxiIUDGn2_Nq"
   },
   "source": [
    "We only leave 2 sequences for validation in order to maximize \n",
    "the amount of training data. For your convenience, here are the\n",
    " LongTermReIDTracker results on them. Your validation IDF1 scores should show an improvement over them.\n",
    "```\n",
    "\n",
    "          IDF1   IDP   IDR  Rcll  Prcn  GT MT PT ML  FP    FN IDs   FM  MOTA  MOTP\n",
    "MOT16-02 45.9% 65.1% 35.4% 52.2% 96.1%  62 12 37 13 390  8873 130  210 49.4% 0.090\n",
    "MOT16-11 68.3% 75.3% 62.5% 80.2% 96.6%  75 44 24  7 266  1871 136   90 75.9% 0.083\n",
    "OVERALL  54.3% 69.6% 44.5% 61.7% 96.3% 137 56 61 20 656 10744 266  300 58.4% 0.087\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7tCJJ3V3Oaa"
   },
   "source": [
    "Let's start training!\n",
    "\n",
    "Note that we have observed quite a lot of noise in validation scores among epochs and runs. This can be explained due to the small size of our training and\n",
    "validation sets, that's why we perform early stopping to obtain the best performing model on validation. In addition, changing the experiment seed and/or relaunching the training might help in case you are suspecting that noise might be influencing your scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQHiwbVr7ot9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- EPOCH  1 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:05,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20. Loss: 0.724. Accuracy: 0.910. Recall: 0.840. Precision: 0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:11,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40. Loss: 0.306. Accuracy: 0.970. Recall: 0.969. Precision: 0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:17,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60. Loss: 0.150. Accuracy: 0.980. Recall: 0.986. Precision: 0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:23,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 80. Loss: 0.097. Accuracy: 0.990. Recall: 0.994. Precision: 0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:28,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100. Loss: 0.157. Accuracy: 0.981. Recall: 0.976. Precision: 0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [00:34,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 120. Loss: 0.103. Accuracy: 0.987. Recall: 0.991. Precision: 0.838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [00:40,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 140. Loss: 0.089. Accuracy: 0.990. Recall: 0.989. Precision: 0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:46,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 160. Loss: 0.104. Accuracy: 0.989. Recall: 0.985. Precision: 0.881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [00:52,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 180. Loss: 0.075. Accuracy: 0.991. Recall: 0.995. Precision: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:58,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200. Loss: 0.079. Accuracy: 0.988. Recall: 0.991. Precision: 0.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [01:04,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 220. Loss: 0.065. Accuracy: 0.993. Recall: 0.993. Precision: 0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [01:10,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 240. Loss: 0.060. Accuracy: 0.993. Recall: 0.994. Precision: 0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [01:15,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 260. Loss: 0.048. Accuracy: 0.996. Recall: 0.993. Precision: 0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280it [01:21,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 280. Loss: 0.037. Accuracy: 0.997. Recall: 0.995. Precision: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:27,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 300. Loss: 0.034. Accuracy: 0.998. Recall: 0.996. Precision: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "320it [01:32,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 320. Loss: 0.028. Accuracy: 0.998. Recall: 0.995. Precision: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [01:38,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 340. Loss: 0.017. Accuracy: 0.999. Recall: 0.999. Precision: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360it [01:44,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 360. Loss: 0.019. Accuracy: 0.999. Recall: 0.997. Precision: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "380it [01:50,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 380. Loss: 0.023. Accuracy: 0.999. Recall: 0.998. Precision: 0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [01:56,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 400. Loss: 0.017. Accuracy: 0.999. Recall: 0.999. Precision: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "420it [02:02,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 420. Loss: 0.035. Accuracy: 0.999. Recall: 0.995. Precision: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "440it [02:08,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 440. Loss: 0.020. Accuracy: 0.998. Recall: 0.997. Precision: 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "460it [02:14,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 460. Loss: 0.048. Accuracy: 0.998. Recall: 0.992. Precision: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "476it [02:19,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: MOT16-02\n",
      "Tracks found: 84\n",
      "Runtime for MOT16-02: 4.6 s.\n",
      "Tracking: MOT16-11\n",
      "Tracks found: 75\n",
      "Runtime for MOT16-11: 5.2 s.\n",
      "Runtime for all sequences: 9.8 s.\n",
      "          IDF1   IDP   IDR  Rcll  Prcn  GT MT PT ML  FP    FN IDs   FM  MOTA  MOTP IDt IDa IDm\n",
      "MOT16-02 43.1% 61.2% 33.2% 52.2% 96.1%  62 11 38 13 390  8873 107  220 49.6% 0.095  74  39  14\n",
      "MOT16-11 63.2% 69.7% 57.8% 80.2% 96.6%  75 44 24  7 266  1871  39   90 76.9% 0.083  41  10  18\n",
      "OVERALL  50.6% 64.9% 41.5% 61.7% 96.3% 137 55 62 20 656 10744 146  310 58.8% 0.090 115  49  32\n",
      "-------- EPOCH  2 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:06,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20. Loss: 0.041. Accuracy: 0.999. Recall: 0.992. Precision: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:11,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40. Loss: 0.042. Accuracy: 0.997. Recall: 0.993. Precision: 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:17,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60. Loss: 0.015. Accuracy: 0.999. Recall: 0.999. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:23,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 80. Loss: 0.014. Accuracy: 0.999. Recall: 0.999. Precision: 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:29,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100. Loss: 0.018. Accuracy: 0.998. Recall: 0.998. Precision: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [00:35,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 120. Loss: 0.009. Accuracy: 1.000. Recall: 0.998. Precision: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [00:40,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 140. Loss: 0.025. Accuracy: 0.998. Recall: 0.998. Precision: 0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:46,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 160. Loss: 0.020. Accuracy: 0.998. Recall: 0.996. Precision: 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [00:52,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 180. Loss: 0.010. Accuracy: 0.999. Recall: 0.998. Precision: 0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:58,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200. Loss: 0.013. Accuracy: 0.999. Recall: 0.999. Precision: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [01:04,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 220. Loss: 0.024. Accuracy: 0.999. Recall: 0.997. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [01:10,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 240. Loss: 0.015. Accuracy: 0.999. Recall: 0.996. Precision: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [01:16,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 260. Loss: 0.017. Accuracy: 0.999. Recall: 0.998. Precision: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280it [01:22,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 280. Loss: 0.016. Accuracy: 0.999. Recall: 0.998. Precision: 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:28,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 300. Loss: 0.016. Accuracy: 1.000. Recall: 0.999. Precision: 0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "320it [01:34,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 320. Loss: 0.014. Accuracy: 0.999. Recall: 0.999. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [01:40,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 340. Loss: 0.017. Accuracy: 0.999. Recall: 0.998. Precision: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360it [01:46,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 360. Loss: 0.016. Accuracy: 0.999. Recall: 0.998. Precision: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "380it [01:52,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 380. Loss: 0.013. Accuracy: 0.999. Recall: 0.998. Precision: 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [01:58,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 400. Loss: 0.014. Accuracy: 0.999. Recall: 0.999. Precision: 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "420it [02:04,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 420. Loss: 0.010. Accuracy: 0.999. Recall: 0.998. Precision: 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "440it [02:10,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 440. Loss: 0.011. Accuracy: 1.000. Recall: 0.999. Precision: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "460it [02:16,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 460. Loss: 0.030. Accuracy: 0.995. Recall: 0.997. Precision: 0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "476it [02:20,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: MOT16-02\n",
      "Tracks found: 128\n",
      "Runtime for MOT16-02: 3.9 s.\n",
      "Tracking: MOT16-11\n",
      "Tracks found: 94\n",
      "Runtime for MOT16-11: 5.4 s.\n",
      "Runtime for all sequences: 9.3 s.\n",
      "          IDF1   IDP   IDR  Rcll  Prcn  GT MT PT ML  FP    FN IDs   FM  MOTA  MOTP IDt IDa IDm\n",
      "MOT16-02 47.0% 66.8% 36.3% 52.2% 96.1%  62 11 38 13 390  8873 110  216 49.6% 0.095  48  68   9\n",
      "MOT16-11 71.8% 79.1% 65.7% 80.2% 96.6%  75 44 24  7 266  1871  38   90 76.9% 0.083  24  18   9\n",
      "OVERALL  56.3% 72.2% 46.2% 61.7% 96.3% 137 55 62 20 656 10744 148  306 58.8% 0.089  72  86  18\n",
      "-------- EPOCH  3 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:05,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20. Loss: 0.020. Accuracy: 0.999. Recall: 0.995. Precision: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:11,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40. Loss: 0.018. Accuracy: 0.997. Recall: 0.999. Precision: 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:17,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60. Loss: 0.013. Accuracy: 0.999. Recall: 0.997. Precision: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:23,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 80. Loss: 0.015. Accuracy: 0.999. Recall: 0.998. Precision: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:28,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100. Loss: 0.009. Accuracy: 0.999. Recall: 0.999. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [00:33,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 120. Loss: 0.007. Accuracy: 0.999. Recall: 0.999. Precision: 0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [00:39,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 140. Loss: 0.022. Accuracy: 0.998. Recall: 0.995. Precision: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:45,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 160. Loss: 0.011. Accuracy: 0.999. Recall: 0.999. Precision: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [00:51,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 180. Loss: 0.012. Accuracy: 0.999. Recall: 0.997. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:57,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200. Loss: 0.010. Accuracy: 0.999. Recall: 1.000. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [01:03,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 220. Loss: 0.015. Accuracy: 0.998. Recall: 0.998. Precision: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [01:08,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 240. Loss: 0.011. Accuracy: 0.999. Recall: 0.999. Precision: 0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [01:14,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 260. Loss: 0.010. Accuracy: 0.999. Recall: 0.999. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280it [01:20,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 280. Loss: 0.011. Accuracy: 0.999. Recall: 1.000. Precision: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [01:25,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 300. Loss: 0.012. Accuracy: 0.999. Recall: 1.000. Precision: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "320it [01:30,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 320. Loss: 0.008. Accuracy: 0.999. Recall: 1.000. Precision: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [01:36,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 340. Loss: 0.014. Accuracy: 0.999. Recall: 0.999. Precision: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360it [01:42,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 360. Loss: 0.017. Accuracy: 0.998. Recall: 0.998. Precision: 0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "380it [01:47,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 380. Loss: 0.021. Accuracy: 0.998. Recall: 0.997. Precision: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [01:52,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 400. Loss: 0.021. Accuracy: 0.998. Recall: 0.999. Precision: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "420it [01:58,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 420. Loss: 0.015. Accuracy: 0.999. Recall: 0.997. Precision: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "440it [02:04,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 440. Loss: 0.015. Accuracy: 0.999. Recall: 0.997. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "460it [02:10,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 460. Loss: 0.011. Accuracy: 0.999. Recall: 0.998. Precision: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "476it [02:14,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: MOT16-02\n",
      "Tracks found: 102\n",
      "Runtime for MOT16-02: 3.9 s.\n",
      "Tracking: MOT16-11\n",
      "Tracks found: 82\n",
      "Runtime for MOT16-11: 5.4 s.\n",
      "Runtime for all sequences: 9.3 s.\n",
      "          IDF1   IDP   IDR  Rcll  Prcn  GT MT PT ML  FP    FN IDs   FM  MOTA  MOTP IDt IDa IDm\n",
      "MOT16-02 46.8% 66.5% 36.1% 52.2% 96.1%  62 11 38 13 390  8873  97  219 49.6% 0.096  56  47  12\n",
      "MOT16-11 70.2% 77.3% 64.2% 80.2% 96.6%  75 44 24  7 266  1871  36   90 77.0% 0.083  30  15  15\n",
      "OVERALL  55.6% 71.2% 45.6% 61.7% 96.3% 137 55 62 20 656 10744 133  309 58.8% 0.090  86  62  27\n",
      "-------- EPOCH  4 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:05,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20. Loss: 0.009. Accuracy: 0.999. Recall: 1.000. Precision: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:11,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40. Loss: 0.007. Accuracy: 0.999. Recall: 1.000. Precision: 0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:17,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60. Loss: 0.013. Accuracy: 0.999. Recall: 0.998. Precision: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:23,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 80. Loss: 0.009. Accuracy: 0.999. Recall: 1.000. Precision: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:27,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks found: 76\n",
      "Runtime for MOT16-11: 5.4 s.\n",
      "Runtime for all sequences: 9.2 s.\n",
      "          IDF1   IDP   IDR  Rcll  Prcn  GT MT PT ML  FP    FN IDs   FM  MOTA  MOTP IDt IDa IDm\n",
      "MOT16-02 44.9% 63.7% 34.6% 52.2% 96.1%  62 11 38 13 390  8873  97  222 49.6% 0.096  69  38  14\n",
      "MOT16-11 64.7% 71.3% 59.2% 80.2% 96.6%  75 44 24  7 266  1871  47   90 76.9% 0.083  44  15  19\n",
      "OVERALL  52.3% 67.0% 42.9% 61.7% 96.3% 137 55 62 20 656 10744 144  312 58.8% 0.090 113  53  33\n",
      "-------- EPOCH  5 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:05,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20. Loss: 0.012. Accuracy: 0.998. Recall: 0.999. Precision: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:11,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40. Loss: 0.007. Accuracy: 0.999. Recall: 1.000. Precision: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:17,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60. Loss: 0.012. Accuracy: 0.999. Recall: 0.997. Precision: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:23,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 80. Loss: 0.013. Accuracy: 0.999. Recall: 0.998. Precision: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:28,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100. Loss: 0.008. Accuracy: 0.999. Recall: 1.000. Precision: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [00:34,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 120. Loss: 0.013. Accuracy: 0.999. Recall: 0.998. Precision: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [00:40,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 140. Loss: 0.012. Accuracy: 0.999. Recall: 0.998. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:46,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 160. Loss: 0.015. Accuracy: 0.999. Recall: 0.998. Precision: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [00:51,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 180. Loss: 0.015. Accuracy: 0.999. Recall: 0.999. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:57,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200. Loss: 0.013. Accuracy: 0.999. Recall: 0.998. Precision: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [01:03,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 220. Loss: 0.012. Accuracy: 0.999. Recall: 1.000. Precision: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [01:08,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 240. Loss: 0.008. Accuracy: 0.999. Recall: 0.999. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [01:14,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 260. Loss: 0.011. Accuracy: 0.999. Recall: 0.998. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280it [01:20,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 280. Loss: 0.009. Accuracy: 0.999. Recall: 1.000. Precision: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:25,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 300. Loss: 0.004. Accuracy: 1.000. Recall: 1.000. Precision: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "321it [01:31,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 320. Loss: 0.013. Accuracy: 0.998. Recall: 0.999. Precision: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [01:36,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 340. Loss: 0.007. Accuracy: 1.000. Recall: 0.999. Precision: 0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360it [01:41,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 360. Loss: 0.011. Accuracy: 0.999. Recall: 0.998. Precision: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "380it [01:47,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 380. Loss: 0.014. Accuracy: 0.999. Recall: 0.999. Precision: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [01:53,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 400. Loss: 0.019. Accuracy: 0.998. Recall: 0.998. Precision: 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "420it [01:58,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 420. Loss: 0.009. Accuracy: 0.999. Recall: 0.999. Precision: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "440it [02:04,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 440. Loss: 0.007. Accuracy: 0.999. Recall: 1.000. Precision: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "460it [02:10,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 460. Loss: 0.006. Accuracy: 0.999. Recall: 1.000. Precision: 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "476it [02:14,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: MOT16-02\n",
      "Tracks found: 89\n",
      "Runtime for MOT16-02: 4.0 s.\n",
      "Tracking: MOT16-11\n",
      "Tracks found: 79\n",
      "Runtime for MOT16-11: 5.5 s.\n",
      "Runtime for all sequences: 9.5 s.\n",
      "          IDF1   IDP   IDR  Rcll  Prcn  GT MT PT ML  FP    FN IDs   FM  MOTA  MOTP IDt IDa IDm\n",
      "MOT16-02 48.5% 68.8% 37.4% 52.2% 96.1%  62 11 38 13 390  8873  98  222 49.6% 0.095  64  44  14\n",
      "MOT16-11 70.3% 77.5% 64.3% 80.2% 96.6%  75 44 24  7 266  1871  36   90 77.0% 0.083  33  13  15\n",
      "OVERALL  56.7% 72.6% 46.5% 61.7% 96.3% 137 55 62 20 656 10744 134  312 58.8% 0.090  97  57  29\n",
      "-------- EPOCH  6 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:05,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20. Loss: 0.018. Accuracy: 0.997. Recall: 0.999. Precision: 0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:11,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40. Loss: 0.011. Accuracy: 0.998. Recall: 0.999. Precision: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:17,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60. Loss: 0.011. Accuracy: 0.998. Recall: 1.000. Precision: 0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:23,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 80. Loss: 0.010. Accuracy: 0.998. Recall: 0.999. Precision: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:29,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100. Loss: 0.009. Accuracy: 0.999. Recall: 0.999. Precision: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [00:35,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 120. Loss: 0.010. Accuracy: 0.999. Recall: 0.998. Precision: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [00:40,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 140. Loss: 0.010. Accuracy: 0.999. Recall: 0.998. Precision: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [00:46,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 160. Loss: 0.006. Accuracy: 1.000. Recall: 1.000. Precision: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [00:52,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 180. Loss: 0.007. Accuracy: 0.999. Recall: 1.000. Precision: 0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:58,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200. Loss: 0.008. Accuracy: 0.999. Recall: 1.000. Precision: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [01:04,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 220. Loss: 0.009. Accuracy: 0.999. Recall: 0.999. Precision: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [01:10,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 240. Loss: 0.010. Accuracy: 0.999. Recall: 1.000. Precision: 0.990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [01:16,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 260. Loss: 0.011. Accuracy: 0.999. Recall: 1.000. Precision: 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280it [01:21,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 280. Loss: 0.008. Accuracy: 0.999. Recall: 1.000. Precision: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [01:27,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 300. Loss: 0.011. Accuracy: 0.998. Recall: 0.998. Precision: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "320it [01:33,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 320. Loss: 0.005. Accuracy: 1.000. Recall: 1.000. Precision: 0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [01:39,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 340. Loss: 0.010. Accuracy: 0.999. Recall: 0.998. Precision: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360it [01:45,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 360. Loss: 0.012. Accuracy: 0.998. Recall: 1.000. Precision: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "380it [01:51,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 380. Loss: 0.006. Accuracy: 1.000. Recall: 1.000. Precision: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [01:56,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 400. Loss: 0.008. Accuracy: 0.999. Recall: 0.999. Precision: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "420it [02:02,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 420. Loss: 0.009. Accuracy: 0.999. Recall: 0.998. Precision: 0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "440it [02:08,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 440. Loss: 0.008. Accuracy: 0.998. Recall: 1.000. Precision: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "455it [02:12,  3.28it/s]"
     ]
    }
   ],
   "source": [
    "best_idf1 = 0.\n",
    "for epoch in range(1, MAX_EPOCHS + 1):\n",
    "    print(f\"-------- EPOCH {epoch:2d} --------\")\n",
    "    train_one_epoch(model = assign_net, data_loader=data_loader, optimizer=optimizer, print_freq=50)\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % EVAL_FREQ == 0:\n",
    "        tracker =  MPNTracker(assign_net=assign_net.eval(), obj_detect=None, patience=MAX_PATIENCE)\n",
    "        val_sequences = MOT16Sequences('MOT16-val2', osp.join(root_dir, 'data/MOT16'), vis_threshold=0.)\n",
    "        res = run_tracker(val_sequences, db=train_db, tracker=tracker, output_dir=None)\n",
    "        idf1 = res.loc['OVERALL']['idf1']\n",
    "        if idf1 > best_idf1:\n",
    "            best_idf1 = idf1\n",
    "            torch.save(assign_net.state_dict(), osp.join(root_dir, 'output', 'best_ckpt.pth'))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            IDF1   IDP   IDR  Rcll  Prcn  GT MT PT ML  FP    FN IDs   FM  MOTA  MOTP IDt IDa IDm\n",
    "    MOT16-02 48.5% 68.8% 37.4% 52.2% 96.1%  62 11 38 13 390  8873  98  222 49.6% 0.095  64  44  14\n",
    "    MOT16-11 70.3% 77.5% 64.3% 80.2% 96.6%  75 44 24  7 266  1871  36   90 77.0% 0.083  33  13  15\n",
    "    OVERALL  56.7% 72.6% 46.5% 61.7% 96.3% 137 55 62 20 656 10744 134  312 58.8% 0.090  97  57  29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5Vbe4g27ot-"
   },
   "source": [
    "# Exercise submission\n",
    "\n",
    "After executing the followinc cell the `Colab Notebooks/cv3dst_exercise/output` directory in your Google Drive should contain multiple `MOT16-XY.txt` files.\n",
    "\n",
    "For the final submission you have to process the test sequences and upload the zipped prediction files to our server. See moodle for a guide how to upload the results.\n",
    "\n",
    "Note that this time, you only have to evaluate three sequences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kJsbbMM7ot_"
   },
   "outputs": [],
   "source": [
    "best_ckpt = torch.load(osp.join(root_dir, 'output', 'best_ckpt.pth'))\n",
    "assign_net.load_state_dict(best_ckpt)\n",
    "\n",
    "tracker =  MPNTracker(assign_net=assign_net.eval(), obj_detect=None, patience=MAX_PATIENCE)\n",
    "test_db = torch.load(osp.join(root_dir, 'data/preprocessed_data/preprocessed_data_test_2.pth'))\n",
    "val_sequences = MOT16Sequences('MOT16-test', osp.join(root_dir, 'data/MOT16'), vis_threshold=0.)\n",
    "run_tracker(val_sequences, db=test_db, tracker=tracker, output_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of CV3DST_Exercise2.ipynb",
   "provenance": [
    {
     "file_id": "1eIT4nfc3DGdosPZU2A5SsOSFZrY8JxhL",
     "timestamp": 1658683163750
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
